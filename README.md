# Performance Benchmarks

This load balancer was stress-tested using `wrk` to evaluate event loop efficiency, connection management, and throughput under heavy concurrent load.

## üìä Latest Benchmark Results

Tested with 400 concurrent connections against 1,000 backend servers (500 IPv4 + 500 IPv6) on localhost.

### Key Metrics
| Metric | Value |
|--------|-------|
| **Throughput** | 40,037 requests/sec |
| **Total Requests** | 1,204,698 (30 seconds) |
| **Data Transferred** | 228.63 MB @ 7.60 MB/sec |
| **Average Latency** | 18.15 ms |
| **Max Latency** | 371.05 ms |
| **Error Rate** | 0.033% (394 errors / 1.2M requests) |

### Test Configuration
```bash
wrk -t12 -c400 -d30s http://localhost:8080/
```

| Parameter | Value |
|-----------|-------|
| **Tool** | wrk (HTTP benchmarking) |
| **Platform** | macOS (Apple Silicon M1) |
| **Concurrency** | 400 simultaneous connections |
| **Threads** | 12 (wrk client threads) |
| **Duration** | 30 seconds |
| **Backend Pool** | 1,000 servers (dual-stack IPv4/IPv6) |
| **Network** | Loopback (127.0.0.1 / ::1) |

---

## üèóÔ∏è Architecture Highlights

The performance is achieved through:

1. **Event-Driven I/O:** kqueue (macOS) provides O(1) event notification
2. **Non-Blocking Sockets:** All I/O operations use `O_NONBLOCK`
3. **Connection Reuse:** HTTP keep-alive reduces TCP handshake overhead
4. **Single-Threaded Event Loop:** Eliminates context switching for I/O operations
5. **Parallel Health Checking:** 50 worker threads monitor 1,000 backends independently

---

## üìö Technical Resources

This project was built using knowledge from:

### Network Programming
- **Beej's Guide to Network Programming** - Comprehensive resource for socket programming, covering Berkeley sockets API, client-server architecture, and TCP/IP fundamentals

### Event-Driven I/O
- **"Kqueue: A generic and scalable event notification facility"** by Jonathan Lemon (USENIX 2001) - Original paper describing the kqueue API design and implementation on FreeBSD/macOS

### Additional Learning
- macOS `kqueue(2)` and `kevent(2)` man pages

---

## üéØ Performance Analysis

### Throughput
- **40,037 req/sec** sustained over 30 seconds
- Processed **1.2M+ requests** without crashes
- Comparable to production load balancers (NGINX: 30-50k, HAProxy: 40-60k req/sec in similar tests)

### Latency Distribution
```
Average:   18.15 ms
Stdev:     33.83 ms
Max:       371.05 ms
P50:       ~12 ms (estimated)
P95:       ~50 ms (estimated)
P99:       ~80 ms (estimated)
```

*Note: Latency measured end-to-end including backend processing time on loopback*

### Reliability
- **0 connection errors** (all 400 connections succeeded)
- **0 timeout errors** (no hung requests)
- **394 read errors** (0.033% - transient connection resets during stress test)
- **99.967% success rate** under sustained heavy load

---

## üìà Performance Comparison

### vs Other Load Balancers (Approximate)

*Note: Direct comparison requires identical test setup. These are reference benchmarks from public sources.*

| Load Balancer | Typical Throughput | Latency (P50) |
|---------------|-------------------|---------------|
| **This Project** | 40k req/sec | ~12-18 ms |
| NGINX | 30-50k req/sec | 10-20 ms |
| HAProxy | 40-60k req/sec | 5-15 ms |
| Envoy | 30-45k req/sec | 15-30 ms |

*All measurements on similar hardware with localhost backends*

---

## üî¨ Implementation Details

### Core Technologies
- **Language:** C++17
- **Event Loop:** kqueue (macOS/BSD)
- **Sockets:** POSIX Berkeley sockets
- **Concurrency:** Single-threaded event loop + multi-threaded health checks
- **Load Balancing:** Round-robin algorithm

### Backend Configuration
- **Count:** 1,000 total (500 IPv4 on ports 3000-3499, 500 IPv6 on ports 3500-3999)
- **Type:** HTTP echo servers (for testing purposes)
- **Response:** ~200 bytes per request
- **Health Checks:** Active monitoring every 5 seconds

---

## ‚ö†Ô∏è Testing Caveats

1. **Localhost Testing:** No real network latency (~0.01ms loopback vs 1-50ms real network)
2. **Simple Backends:** Echo servers have minimal processing time
3. **macOS Specific:** kqueue performance; epoll on Linux may differ slightly
4. **Single Machine:** Both client and server on same hardware (resource contention)

Real-world performance will vary based on:
- Network latency and packet loss
- Backend processing time
- Hardware specifications
- Operating system and kernel tuning

---

## üöÄ How to Reproduce

### Prerequisites
```bash
# Install wrk
brew install wrk  # macOS

# Build the load balancer
cmake -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build
```

### Run Benchmark
```bash
# Terminal 1: Start load balancer
./build/LoadBalancer

# Terminal 2: Start backend servers
# (Setup 1,000 servers on ports 3000-3999)

# Terminal 3: Benchmark
wrk -t12 -c400 -d30s http://localhost:8080/
```

---

## üéØ Key Takeaways

This load balancer demonstrates:
- Production-grade throughput (40k req/sec)
- Event-driven architecture efficiency (kqueue)
- Proper connection lifecycle management
- Scalability to 1,000 backends
- Reliability under sustained load (99.97% success rate)

**Built from scratch in C++ using low-level systems programming.**
